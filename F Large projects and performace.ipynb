{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ME2_ryels7L"
   },
   "source": [
    "# Package Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsT_nU1gB6-r"
   },
   "source": [
    "## Basic Workflow\n",
    "The simplest way to write a Julia program is to create a `.jl` file somewhere and run it using `julia`. You would usually do this with your favorite editor, but in this notebook we must do this programmatically. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sRL8oZDaC0PX",
    "outputId": "2576e9a6-37ab-4208-ce71-98089f4a671b"
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "println(\"Hello world\")\n",
    "\"\"\"\n",
    "\n",
    "open(f->write(f, code), \"my_program1.jl\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3LsIKh47R99"
   },
   "source": [
    "Then let's run the program using a shell command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UvfGZxERDv6c",
    "outputId": "370bae01-5114-4d5f-f71e-a7d498f9bbdb"
   },
   "outputs": [],
   "source": [
    ";julia my_program1.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmDPtknrD0Al"
   },
   "source": [
    "If you need to use a package which is not part of the standard library, such as `PyCall`, you first need to install it using Julia's package manager `Pkg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "doKyY1qWEMZV",
    "outputId": "8548893b-dd0c-40ee-c915-f6bb9219ee64"
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"PyCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQj8OgUKERBz"
   },
   "source": [
    "Alternatively, in interactive mode, you can enter the `Pkg` mode by typing `]`, then type a command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "KGyakk8GEf84",
    "outputId": "0b0dd9f6-827c-4784-fcda-af476aa14d61"
   },
   "outputs": [],
   "source": [
    "]add PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsGGVOPzEkj9"
   },
   "source": [
    "You can also precompile the new package to avoid the compilation delay when the package is first used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "GqYovSwVEihb",
    "outputId": "bf601d8f-18d5-4fe4-8171-051751acc833"
   },
   "outputs": [],
   "source": [
    "]add PyCall; precompile;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMwXNbzGExCn"
   },
   "source": [
    "One last alternative is to use `pkg\"...\"` strings to run commands in your programs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "tx5hdeO9E71F",
    "outputId": "f13fa111-68bc-4374-b068-4c8457abcfe5"
   },
   "outputs": [],
   "source": [
    "pkg\"add PyCall; precompile;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEIWFBgnFC6c"
   },
   "source": [
    "Now you can import `PyCall` in any of your Julia programs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9kTp497AFJuT",
    "outputId": "65610125-ecae-4be5-cc93-96d50c2ab203"
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "using PyCall\n",
    "py\"print('1 + 2 =', 1 + 2)\"\n",
    "\"\"\"\n",
    "\n",
    "open(f->write(f, code), \"my_program2.jl\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "unfHQR31FVf1",
    "outputId": "4b147b47-cf3e-43a3-ec79-4ff062e8b59e"
   },
   "outputs": [],
   "source": [
    ";julia my_program2.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Cd3wPG9PH-p"
   },
   "source": [
    "You can also add packages by providing their URL (typically on github). This is useful when you want to use a package which is not in the [official Julia Package registry](https://github.com/JuliaRegistries/General), or when you want the very latest version of a package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "cW6k8F91PT23",
    "outputId": "b5ce446f-43a0-4b09-f19c-cdbc03a9a113"
   },
   "outputs": [],
   "source": [
    "]add https://github.com/JuliaLang/Example.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtRAtwWkD3Ao"
   },
   "source": [
    "You can install a specific package version like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "CceFEwcTCAWG",
    "outputId": "75678658-ea0b-460a-8b30-7642aff97288"
   },
   "outputs": [],
   "source": [
    "]add PyCall@1.91.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlN_f9jpGPO1"
   },
   "source": [
    "If you only specify version `1` or version `1.91`, Julia will get the latest version with that prefix. For example, `]add PyCall@0.91` would install the latest version `0.91.x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDixUMn7DDri"
   },
   "source": [
    "You can also update a package to its latest version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "0EQofpkzD4xq",
    "outputId": "59075dfb-d549-4323-cf58-a2311c546266"
   },
   "outputs": [],
   "source": [
    "]update PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgeDVp26DI7_"
   },
   "source": [
    "You can update all packages to their latest versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "S3Mi-zgLDOVw",
    "outputId": "56b9f42b-5005-483f-dd06-8b3bb69e9904"
   },
   "outputs": [],
   "source": [
    "]update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C6nNERsDa_M"
   },
   "source": [
    "If you don't want a particular package to be updated the next time you call `]update`, you can pin it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Nht6o2uCDiiL",
    "outputId": "b5b859c1-c753-48db-cdc1-4145bf4a00b9"
   },
   "outputs": [],
   "source": [
    "]pin PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qp9v2d7tDxjH"
   },
   "source": [
    "To unpin the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "3i9JoQimDl7I",
    "outputId": "3684dacf-3105-49df-a84f-8dcfe11310ae"
   },
   "outputs": [],
   "source": [
    "]free PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Asr1snFp609f"
   },
   "source": [
    "You can also run the tests defined in a package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "XlmKnEvf67zi",
    "outputId": "2eaedf96-f0b6-4841-d46a-620aae16ecd9"
   },
   "outputs": [],
   "source": [
    "]test Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHAXzij6ZPPs"
   },
   "source": [
    "Of course, you can remove a package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2fuEjhjzZROg",
    "outputId": "8b10f6ba-994d-47d9-ab50-1284ca582ea4"
   },
   "outputs": [],
   "source": [
    "]rm Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eeTA6D33CHTv"
   },
   "source": [
    "Lastly, you can check which packages are installed using `]status` (or `]st` for short):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "lSqzm_yECL6Y",
    "outputId": "329baf41-b7c2-4ed5-de58-a326a969a2dc"
   },
   "outputs": [],
   "source": [
    "]st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVwtyjNJlL5j"
   },
   "source": [
    "For more `Pkg` commands, type `]help`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQY6BRiBvdbU"
   },
   "source": [
    "|Julia (in interactive mode) | Python (in a terminal)\n",
    "|-----|------\n",
    "|`]status` | `pip freeze`<br />or<br />`conda list`\n",
    "|`]add Foo` | `pip install foo`<br />or<br />`conda install foo`\n",
    "|`]add Foo@1.2` | `pip install foo==1.2`<br />or<br />`conda install foo=1.2`\n",
    "|`]update Foo` | `pip install --upgrade foo`<br />or<br />`conda update foo`\n",
    "|`]pin Foo` | `foo==<version>` in `requirements.txt`<br /> or<br />`foo=<version>` in `environment.yml`\n",
    "|`]free Foo` | `foo` in `requirements.txt`<br />or<br />`foo` in `environment.yml`\n",
    "|`]test Foo` | `python -m unittest foo`\n",
    "|`]rm Foo` | `pip uninstall foo`<br />or<br />`conda remove foo`\n",
    "|`]help` | `pip --help`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6KvuaMcFx2N"
   },
   "source": [
    "This workflow is fairly simple, but it means that all of your programs will be using the same version of each package. This is analog to installing packages using `pip install` without using virtual environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaJvX0RcqukU"
   },
   "source": [
    "\n",
    "## Projects\n",
    "\n",
    "If you want to have multiple projects, each with different libraries and library versions, you should define **projects**. These are analog to Python virtual environments.\n",
    "\n",
    "A project is just a directory containing a `Project.toml` file and a `Manifest.toml` file:\n",
    "\n",
    "```\n",
    "my_project/\n",
    "    Project.toml\n",
    "    Manifest.toml\n",
    "```\n",
    "\n",
    "* `Project.toml` is similar to a `requirements.txt` file (for pip) or `environment.yml` (for conda): it lists the dependencies of the project, and compatibility constraints (e.g., `SomeDependency = 2.5`).\n",
    "* `Manifest.toml` is an automatically generated file which lists the exact versions and unique IDs (UUIDs) of all the packages that Julia found, based on `Project.toml`. It includes all the implicit dependencies of the project's packages. This is useful to reproduce an environment precisely. Analog to the output of `pip --freeze`.\n",
    "\n",
    "By default, the active project is located in `~/.julia/environments/v#.#` (where `#.#` is the Julia version you are using, such as 1.4). You can set a different project when starting Julia:\n",
    "\n",
    "```bash\n",
    "# BASH\n",
    "julia --project=/path/to/my_project\n",
    "```\n",
    "\n",
    "Or you can set the `JULIA_PROJECT` environment variable:\n",
    "\n",
    "```bash\n",
    "# BASH\n",
    "export JULIA_PROJECT=/path/to/my_project\n",
    "julia\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84iGO38zM3Cz"
   },
   "source": [
    "Or you can just activate a project directly in Julia (this is analog to running `source my_project/env/bin/activate` when using virtualenv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tuXofzisM-bW",
    "outputId": "9bf468ff-da50-4cfd-96c3-12343e16a107"
   },
   "outputs": [],
   "source": [
    "Pkg.activate(\"my_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOPtEC3UNTsh"
   },
   "source": [
    "The `my_project` directory does not exist yet, but it gets created automatically, along with the `Project.toml` and `Manifest.toml` files, when you first add a package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "yLuWH7U8g84W",
    "outputId": "de641ac5-5502-4095-cf86-48b64414ecbd"
   },
   "outputs": [],
   "source": [
    "]add PyCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KS6OJjVpTcKX"
   },
   "source": [
    "You can also add a package via its URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ydZSoyULOlwV",
    "outputId": "2923c9fd-bac0-4f4f-b17b-bb915874f56a"
   },
   "outputs": [],
   "source": [
    "]add https://github.com/JuliaLang/Example.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKr9G4fDGGLv"
   },
   "source": [
    "Let's also add a package with a specific version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xM8l4uR2GJsM",
    "outputId": "7ebb9997-153b-4fbb-98d1-773d74a32f12"
   },
   "outputs": [],
   "source": [
    "]add Example@0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCZ-eWicTmVx"
   },
   "source": [
    "Now the `Project.toml` and `Manifest.toml` files were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CPbncHi09yFJ",
    "outputId": "8f9d4bb4-e3f1-42bc-88e8-b5af5c34f0bd"
   },
   "outputs": [],
   "source": [
    ";find my_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jw-VCU41Ua7A"
   },
   "source": [
    "Notice that the packages we added to the project were _not_ placed in the `my_project` directory itself. They were saved in the `~/.julia/packages` directory, the compiled files were placed in `~/.julia/compiled` director, logs were written to `~/.julia/logs` and so on.\n",
    "\n",
    "If several projects use the same package, it will only be downloaded and built once (well, once per version). The `~/.julia/packages` directory can hold multiple versions of the same package, so it's fine if different projects use different versions of the same package. There will be no conflict, no \"dependency hell\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9yjyihUisIK"
   },
   "source": [
    "The `Project.toml` just says that the project depends on `PyCall` and `Example`, and it specifies the UUID of this package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Gz8KscpIhIX4",
    "outputId": "db96f24f-931b-483c-eb7f-cdfead0195d5"
   },
   "outputs": [],
   "source": [
    "print(read(\"my_project/Project.toml\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpxulMt32SFf"
   },
   "source": [
    "UUIDs are useful to avoid name conflicts. If several people name their package `CoolStuff`, then the UUID will clarify which one we are referring to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_mbX8HUi7Qg"
   },
   "source": [
    "The `Manifest.toml` file is much longer, since it contains all the packages which `PyCall` and `Example` depend on, along with their versions (except for the standard library packages), and the dependency graph. This file should never be modified manually:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "28qXSoSwhOgm",
    "outputId": "7ee5c474-9d2e-432d-95c1-5a09023de43e"
   },
   "outputs": [],
   "source": [
    "print(read(\"my_project/Manifest.toml\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1JJXmuz1LPl"
   },
   "source": [
    "Note that `Manifest.toml` contains the precise version of the `Example` package that was installed, but the `Project.toml` file does not specify that version `0.3` is required. That's because Julia cannot know whether your project is supposed to work only with any version `0.3.x`, or whether it could work with other versions as well. So if you want to specify a version constraint for the `Example` package, you must add it manually in `Project.toml`. You would normally use your favorite editor to do this, but in this notebook we'll update `Project.toml` programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tgddc3M_1iyG",
    "outputId": "b5b5fd32-facb-4cbd-def6-5d6161c7ca44"
   },
   "outputs": [],
   "source": [
    "append_config = \"\"\"\n",
    "\n",
    "[compat]\n",
    "Example = \"0.3\"\n",
    "\"\"\"\n",
    "\n",
    "open(f->write(f, append_config), \"my_project/Project.toml\", \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BD4rgzAT2GGs"
   },
   "source": [
    "Here is the updated `Project.toml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "XNAC8q0H17mI",
    "outputId": "85e08912-3818-4498-dfd7-d44ec9a74b13"
   },
   "outputs": [],
   "source": [
    "print(read(\"my_project/Project.toml\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VyWAJoEq6GZs"
   },
   "source": [
    "Now if we try to replace `Example` 0.3 with version 0.2, we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qgBa7Y0x6NUm",
    "outputId": "b4e03b71-d3e3-4d6f-8bfa-544ec23920ab"
   },
   "outputs": [],
   "source": [
    "try\n",
    "    pkg\"add Example@0.2\"\n",
    "catch ex\n",
    "    ex\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3zvTUWSH4Sa"
   },
   "source": [
    "Now you can run a program based on this project, and it will have the possibility to use all the packages which have been added to this project, with their specific versions. If you import a package which was not explicitly added to this project, Julia will fallback to the default project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XnSjhJSyISzT",
    "outputId": "b2676e79-f354-4908-f9f1-6e41a81d7351"
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import PyCall # found in the project\n",
    "import PyPlot # not found, so falls back to default project\n",
    "println(\"Success!\")\n",
    "\"\"\"\n",
    "\n",
    "open(f->write(f, code), \"my_program3.jl\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eM4yXtogIc5d",
    "outputId": "172e5e76-59c5-4898-fca6-d1858082bc33"
   },
   "outputs": [],
   "source": [
    ";julia --project=my_project my_program3.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3C_z11CDXzJ"
   },
   "source": [
    "## Packages\n",
    "Falling back to the default project is fine, as long as you run the code on your own machine, but if you want to share your code with other people, it would be brittle to count on packages installed in _their_ default project. Instead, if you plan to share your code, you should clearly specify which packages it depends on, and use only these packages. Such a shareable project is called a **package**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cLqsDTlMRM9"
   },
   "source": [
    "A package is a regular project (as defined above), but with a few extras:\n",
    "* the `Project.toml` file must specify a `name`, a `version` and a `uuid`.\n",
    "* there must be a `src/PackageName.jl` file containing a module named `PackageName`.\n",
    "* you generally want to specify the `authors` and `description`, and maybe also the `license`, `repository` (e.g., the package's github URL), and some `keywords`, but all of these are optional.\n",
    "\n",
    "It is very easy to create a new package using the `]generate` command. To define the `authors` field, `Pkg` will look up the `user.name` and `user.email` git config entries, so let's define them before we generate the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lrw9Diey5Jw"
   },
   "outputs": [],
   "source": [
    ";git config --global user.name \"Alice Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHImoacOzHyR"
   },
   "outputs": [],
   "source": [
    ";git config --global user.email \"alice.bob@example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bTw_L-4-ls4H",
    "outputId": "c13f7a4a-9cad-4212-c9bc-b59c6088fc86"
   },
   "outputs": [],
   "source": [
    "]generate MyPackages/Hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OvnM3tBpW9X"
   },
   "source": [
    "This generated the `MyPackages/Hello/Project.toml` file (along with the enclosing directories) and the `MyPackages/Hello/src/Hello.jl` file. Let's take a look at the `Project.toml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wQqVtTh5qkhm",
    "outputId": "49fe342c-0d1e-483b-e2fe-dc5db18310b4"
   },
   "outputs": [],
   "source": [
    "print(read(\"MyPackages/Hello/Project.toml\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1IL7fuyiAtb"
   },
   "source": [
    "Notice that the project has no dependencies yet, but it has a name, a unique UUID, and a version (plus an author)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pgs4xop1qr1z"
   },
   "source": [
    "Note: if `Pkg` does not find a your name or email in the git config, it falls back to environment variables (`GIT_AUTHOR_NAME`, `GIT_COMMITTER_NAME`, `USER`, `USERNAME`, `NAME` and `GIT_AUTHOR_EMAIL`, `GIT_COMMITTER_EMAIL`, `EMAIL`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSyvL2-I0S_t"
   },
   "source": [
    "And let's look at the `src/Hello.jl` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Y4DvJfrC0W_u",
    "outputId": "d8a7a483-2d15-4e89-b3f3-91bef30c2d89"
   },
   "outputs": [],
   "source": [
    "print(read(\"MyPackages/Hello/src/Hello.jl\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6orcK-WH1dv8"
   },
   "source": [
    "Let's try to use the `greet()` function from the `Hello` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9ASQUXed1jR9",
    "outputId": "759e1526-6d65-450b-d88f-bb7ce29588ea"
   },
   "outputs": [],
   "source": [
    "try\n",
    "    import Hello\n",
    "    Hello.greet()\n",
    "catch ex\n",
    "    ex\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ehdlz0d51pRY"
   },
   "source": [
    "Julia could not find the `Hello` package. When you're working on a package, don't forget to activate it first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "geOkTHsh10es",
    "outputId": "91dfa66e-2235-4eb0-a334-acb5124d1cf8"
   },
   "outputs": [],
   "source": [
    "]activate MyPackages/Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aN3bg65b137-",
    "outputId": "8b9e5264-cd19-48d3-ab46-7b497163ae23"
   },
   "outputs": [],
   "source": [
    "import Hello\n",
    "Hello.greet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WxXCSYwIE9Eo"
   },
   "source": [
    "It works!\n",
    "\n",
    "If the `Hello` package depends on other packages, we must add them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "cZfLcJO3-m9D",
    "outputId": "31c7a045-67ca-431a-fe50-012f29e05835"
   },
   "outputs": [],
   "source": [
    "]add PyCall Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcipxHQW91lp"
   },
   "source": [
    "You must not use any package which has not been added to the project. If you do, you will get a warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MyUldzLAFZn"
   },
   "source": [
    "Once you are happy with your package, you can deploy it to github (or anywhere else). Then you can add it to your own projects just like any other package.\n",
    "\n",
    "If you want to make your package available to the world via the official Julia registry, you just need to send a Pull Request to https://github.com/JuliaRegistries/General. However, it's highly recommended to automate this using the [Registrator.jl](https://github.com/JuliaRegistries/Registrator.jl) github app.\n",
    "\n",
    "If you want to use other registries (including private registries), check out [this page](https://julialang.github.io/Pkg.jl/v1.4/registries/#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNd3-22NIkfB"
   },
   "source": [
    "Also check out the [`PkgTemplate`](https://github.com/invenia/PkgTemplates.jl) package, which provides more sophisticated templates for creating new packages, for example with continuous integration, code coverage tests, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeVc0WCoJ_yl"
   },
   "source": [
    "## Fixing Issues in a Dependency\n",
    "Sometimes you may run into an issue inside one of the packages your project depends on. When this happens, you can use `Pkg`'s `dev` command to fix the issue. For example, let's pretend the `Example` package has a bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "HwIRORxQKcxn",
    "outputId": "13b7ff24-6d98-482a-d864-8586ade4d55c"
   },
   "outputs": [],
   "source": [
    "]dev Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e63oY5HKgVD"
   },
   "source": [
    "This command cloned the repo into `~/.julia/dev/Example`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WV77BYAPK-ff",
    "outputId": "30c24d7a-8d2e-44d1-9e58-ebb3cce523cc"
   },
   "outputs": [],
   "source": [
    ";ls -l \"~/.julia/dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pB4nAoM2MmlI"
   },
   "source": [
    "It also updated the `Hello` package's `Manifest.toml` file to ensure the package now uses the `Example` clone. You can see this using `]status`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UldZNewDMYaf",
    "outputId": "af7efd7a-61b0-4ce4-986b-f770d81016c0"
   },
   "outputs": [],
   "source": [
    "]st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OY080wXKK85W"
   },
   "source": [
    "So you would now go ahead and edit the clone and fix the bug. Of course, you would also want to send a PR to the package's owners so the source package gets fixed. Once that happens, you can go back to the official `Example` package easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "6Ju_ehk6K4fi",
    "outputId": "51bc760e-8583-4897-a32a-b61abbdc6427"
   },
   "outputs": [],
   "source": [
    "]free Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gZNtvkp0NdQt",
    "outputId": "aebe4d82-7ca0-4b23-d80a-c7f482ee86f2"
   },
   "outputs": [],
   "source": [
    "]st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjk0y4x4X3OC"
   },
   "source": [
    "## Instantiating a Project\n",
    "If you want to run someone else's project and you want to make sure you are using the exact same package versions, you can clone the project, and assuming it has a `Manifest.toml` file, you can activate the project and run `]instantiate` to install all the appropriate packages. For example, let's instantiate the `Registrator.jl` project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ukq2x0oKYUzv",
    "outputId": "e1da02e2-81d4-4703-9859-aa7547cc3ffc"
   },
   "outputs": [],
   "source": [
    ";git clone https://github.com/JuliaRegistries/Registrator.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eP8xWq-lYqIe",
    "outputId": "44d501cc-1fcf-48b9-f926-9097278fbfe1"
   },
   "outputs": [],
   "source": [
    "]activate Registrator.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "mWTuYYjPYtRV",
    "outputId": "bf51d7bd-4f9d-4bac-fa99-7269d84e9e35"
   },
   "outputs": [],
   "source": [
    "]instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoMg99bTtFDp"
   },
   "source": [
    "Usually, that's all you need to know about projects and packages, but let's look at bit under the hood, so you can handle less common cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8Y6A_IuepPI"
   },
   "source": [
    "## Load Path\n",
    "When you import a package, Julia searches for it in the environments listed in the `LOAD_PATH` array. An **environment** can be a project or a directory containing a bunch of packages directly. By default, the `LOAD_PATH` array contains three elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wpSWi2epgdpk",
    "outputId": "a49e47d2-2c00-4ea4-9ccf-906848f171c8"
   },
   "outputs": [],
   "source": [
    "LOAD_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hH-S7BL9iuN4"
   },
   "source": [
    "Here's what these elements mean:\n",
    "* `\"@\"` represents the active project, if any: that's the project activated via `--project`, `JULIA_PROJECT`, `]activate` or `Pkg.activate()`.\n",
    "* `\"@v#.#\"` represents the default shared project for the version of Julia we are running. That's why it is used by default when there is no active project.\n",
    "* `\"@stdlib\"` represents the standard library. This is not a project: it's a directory containing many packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHbG_HsOP8O7"
   },
   "source": [
    "If you want to see the actual paths, you can call `Base.load_path()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "oGya8XxwQDJz",
    "outputId": "4920e872-0a7f-44d6-f033-c8ef06ab03ee"
   },
   "outputs": [],
   "source": [
    "Base.load_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaIw9vRxLVVt"
   },
   "source": [
    "You can change the load path if you want to. For example, if you want Julia to look only in the active project and in the standard library, without looking in the default project, then you can set the `JULIA_LOAD_PATH` environment variable to `\"@:@stdlib\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8EScSOrdb3ha"
   },
   "source": [
    "If you try to run `my_program3.jl` this way, it will successfully import `PyCall`, but it will fail to import `PyPlot`, since it is not listed in `Project.toml` (however, it would successfully import any package from the standard library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "sN2NunpdLgKR",
    "outputId": "ed0993d7-2459-4ed3-9ef4-34776cbc33ed"
   },
   "outputs": [],
   "source": [
    "try\n",
    "    withenv(\"JULIA_LOAD_PATH\"=>\"@:@stdlib\") do\n",
    "        run(`julia --project=my_project my_program3.jl`)\n",
    "    end\n",
    "catch ex\n",
    "    ex\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrLpiVS2UG9S"
   },
   "source": [
    "You can also modify the `LOAD_PATH` array programmatically, for example to make all the packages in the `my_packages/` directory available to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "8kGSkqsVULfC",
    "outputId": "46a6184a-8cd7-49c6-99bc-2544e8e63a1c"
   },
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, \"my_packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_fpeCNoRARJ"
   },
   "source": [
    "Now any package added to this directory will be directly available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3C42rrfKQ01y",
    "outputId": "d9454fb2-aa21-461d-fc3d-73073dfb8ec5"
   },
   "outputs": [],
   "source": [
    "]generate my_packages/Hello2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ClgC-rhWQ9XP",
    "outputId": "8a52d053-3168-4e99-d804-1e724df99618"
   },
   "outputs": [],
   "source": [
    "using Hello2\n",
    "Hello2.greet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kkX-WKARP0l"
   },
   "source": [
    "This is a convenience for development, as we didn't have to push this package to a repository or even add it to the project. However, it's just for development: once you're happy with your package, make sure to push it to a repo, and add it to the project normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1V5pYziAzWG"
   },
   "source": [
    "## Depots\n",
    "As we saw earlier, new packages you add to a project are placed in the `~/.julia/packages` directory, logs are placed in `~/.julia/logs`, and so on.\n",
    "\n",
    "A directory like `~/.julia` which contains `Pkg` related content is called a **depot**. Julia installs all new packages in the default depot, which is the first directory in the `DEPOT_PATH` array (this array can be modified manually in Julia, or set via the `JULIA_DEPOT_PATH` environment variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "r4y3Uarp-VXi",
    "outputId": "bc820ca0-9126-4423-c1a6-d05ddf04b858"
   },
   "outputs": [],
   "source": [
    "DEPOT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg_JLf9R-geB"
   },
   "source": [
    "The default depot needs to be writeable for the current user, since that's where new packages will be written to (as well as logs and other stuff). The other depots can be read-only: they're typically used for private package registries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAJBZg_RXUqj"
   },
   "source": [
    "You can occasionally run the `]gc` command, which will remove all unused package versions (`Pkg` will use the logs to located existing projects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uhHgsN2WUG_"
   },
   "source": [
    "In summary: when some code runs `using Foo` or `import Foo`, the `LOAD_PATH` is used to determine _which_ specific package `Foo` refers to, while the `DEPOT_PATH` is used to determine _where_ it is. The exception is when the `LOAD_PATH` contains directories which directly contain packages: for these packages, the `DEPOT_PATH` is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgeH4A06IIX4"
   },
   "source": [
    "# Parallel Computing\n",
    "Julia supports coroutines (aka green threads), multithreading (without a [GIL](https://en.wikipedia.org/wiki/Global_interpreter_lock#:~:text=A%20global%20interpreter%20lock%20(GIL,on%20a%20multi%2Dcore%20processor.) like CPython!), multiprocessing and distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVCHhzbYFUv5"
   },
   "source": [
    "## Coroutines\n",
    "Let's go back to the `fibonacci()` generator function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "LHQ6czbxItEw",
    "outputId": "d2570925-32ed-486c-ccb7-53fd06b6ee2c"
   },
   "outputs": [],
   "source": [
    "function fibonacci(n)\n",
    "    Channel() do ch\n",
    "        a, b = 1, 1\n",
    "        for i in 1:n\n",
    "            put!(ch, a)\n",
    "            a, b = b, a + b\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "for f in fibonacci(10)\n",
    "    println(f)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgDS2AjiVljr"
   },
   "source": [
    "Under the hood, `Channel() do ... end` creates a `Channel` object, and spawns an asynchronous `Task` to execute the code in the `do ... end` block. The task is scheduled to execute immediately, but when it calls the `put!()` function on the channel to yield a value, it blocks until another task calls the `take!()` function to grab that value. You do not see the `take!()` function explicitly in this code example, since it is executed automatically in the `for` loop, in the main task. To demonstrate this, we can just call the `take!()` function 10 times to get all the items from the channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "-tff7DpqbK-J",
    "outputId": "cc371eca-0c65-4501-e84f-ab9b3e55c737"
   },
   "outputs": [],
   "source": [
    "ch = fibonacci(10)\n",
    "for i in 1:10\n",
    "    println(take!(ch))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUZjr1wHdc5y"
   },
   "source": [
    "This channel is bound to the task, therefore it is automatically closed when the task ends. So if we try to get one more element, we will get an exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9eJjrbrHdU33",
    "outputId": "7c9de9c3-a345-4ef1-bc19-417d3798a92f"
   },
   "outputs": [],
   "source": [
    "try\n",
    "    take!(ch)\n",
    "catch ex\n",
    "    ex\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLvvfxZznXps"
   },
   "source": [
    "Here is a more explicit version of the `fibonacci()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FSP1vZjheZDJ",
    "outputId": "1969105f-4b28-4d3d-df88-b1b4ff4fbffa"
   },
   "outputs": [],
   "source": [
    "function fibonacci(n)\n",
    "  function generator_func(ch, n)\n",
    "    a, b = 1, 1\n",
    "    for i in 1:n\n",
    "        put!(ch, a)\n",
    "        a, b = b, a + b\n",
    "    end\n",
    "  end\n",
    "  ch = Channel()\n",
    "  task = @task generator_func(ch, n) # creates a task without starting it\n",
    "  bind(ch, task) # the channel will be closed when the task ends\n",
    "  schedule(task) # start running the task asynchronously\n",
    "  ch\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KnzQbUGonIJ"
   },
   "source": [
    "And here is a more explicit version of the `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ir3FUJAEoD5j",
    "outputId": "3e862089-d9a0-40b8-bb82-91a24480c88c"
   },
   "outputs": [],
   "source": [
    "ch = fibonacci(10)\n",
    "while isopen(ch)\n",
    "  value = take!(ch)\n",
    "  println(value)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTwMO7gxpCSa"
   },
   "source": [
    "Note that asynchronous tasks (also called \"coroutines\" or \"green threads\") are not actually run in parallel: they cooperate to alternate execution. Some functions, such as `put!()`, `take!()`, and many I/O functions, interrupt the current task's execution, at which point it lets Julia's scheduler decide which task should resume its execution. This is just like Python's coroutines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTiiI6ZfbKKQ"
   },
   "source": [
    "For more details on coroutines and tasks, see [the manual](https://docs.julialang.org/en/v1/manual/control-flow/#man-tasks-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9dzuKC2qFRL"
   },
   "source": [
    "## Multithreading\n",
    "Julia also supports multithreading. Currently, you need to specify the number of O.S. threads upon startup, by setting the `JULIA_NUM_THREADS` environment variable (or setting the `-t` argument in Julia 1.5+). In the first cell, we configured the IJulia kernel so that set environment variable is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mBYUWpQpDBzS",
    "outputId": "4b93ccaf-a04c-43d1-d32f-f0558fc9fc91"
   },
   "outputs": [],
   "source": [
    "ENV[\"JULIA_NUM_THREADS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AK8aRLqEhJt"
   },
   "source": [
    "The actual number of threads started by Julia may be lower than that, as it is limited to the number of available cores on the machine (thanks to hyperthreading, each physical core may run two threads). Here is the number of threads that were actually started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KjEv4FOwEQhl",
    "outputId": "8c14d637-f9fd-43b6-85b0-a8667cf2bece"
   },
   "outputs": [],
   "source": [
    "using Base.Threads\n",
    "nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tc3bXp57DINZ"
   },
   "source": [
    "Now let's run 10 tasks across these threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "ic1ecJ-1qatN",
    "outputId": "55fd971f-c402-4f49-ad4e-0909723fc04c"
   },
   "outputs": [],
   "source": [
    "@threads for i in 1:10\n",
    "    println(\"thread #\", threadid(), \" is starting task #$i\")\n",
    "    sleep(rand()) # pretend we're actually working\n",
    "    println(\"thread #\", threadid(), \" is finished\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHpLG3h7LVMm"
   },
   "source": [
    "Here is a multithreaded version of the `estimate_pi()` function. Each thread computes part of the sum, and the parts are added at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mDHzyNqdJswG",
    "outputId": "40f3533e-59ad-4796-dde7-e71e771f72a3"
   },
   "outputs": [],
   "source": [
    "function parallel_estimate_pi(n)\n",
    "    s = zeros(nthreads())\n",
    "    nt = n ÷ nthreads()\n",
    "    @threads for t in 1:nthreads()\n",
    "        for i in (1:nt) .+ nt*(t - 1)\n",
    "          @inbounds s[t] += (isodd(i) ? -1 : 1) / (2i + 1)\n",
    "        end\n",
    "    end\n",
    "    return 4.0 * (1.0 + sum(s))\n",
    "end\n",
    "\n",
    "@btime parallel_estimate_pi(100_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Ql0KLRNSqNg"
   },
   "source": [
    "The `@inbounds` macro is an optimization: it tells the Julia compiler not to add any bounds check when accessing the array. It's safe in this case since the `s` array has one element per thread, and `t` varies from `1` to `nthreads()`, so there is no risk for `s[t]` to be out of bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVftN7gXQCOh"
   },
   "source": [
    "Let's compare this with the single-threaded implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F2Yfz67kK2xX",
    "outputId": "f1dee2aa-984b-48e7-cd8a-eebd2e8e224e"
   },
   "outputs": [],
   "source": [
    "@btime estimate_pi(100_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnOKCxlNQX01"
   },
   "source": [
    "If you are running this notebook on Colab, the parallel implementation is probably no faster than the single-threaded one. That's because the Colab Runtime only has a single CPU, so there is no benefit from multithreading (plus there is a bit of overhead for managing threads). However, on my 8-core machine, using 16 threads, the parallel implementation is about 6 times faster than the single-threaded one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOUeRI6DRbmo"
   },
   "source": [
    "Julia has a `mapreduce()` function which makes it easy to implement functions like `parallel_estimate_pi()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c04i5fsvO5m5",
    "outputId": "6058add9-2f60-4408-f951-6a2bbe613687"
   },
   "outputs": [],
   "source": [
    "function parallel_estimate_pi2(n)\n",
    "    4.0 * mapreduce(i -> (isodd(i) ? -1 : 1) / (2i + 1), +, 0:n)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZHKduTA-PW5T",
    "outputId": "6276a5dd-8855-4383-d47e-cd942eac79b5"
   },
   "outputs": [],
   "source": [
    "@btime parallel_estimate_pi2(100_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Lwb_H7vTeCg"
   },
   "source": [
    "The `mapreduce()` function is well optimized, so it's about twice faster than `parallel_estimate_pi()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0PXPosbamtW"
   },
   "source": [
    "You can also spawn a task using `Threads.@spawn`. It will get executed on any one of the running threads (it will not start a new thread):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "w2YYrw3IYX4v",
    "outputId": "fef92ece-9ee0-40b2-a1c0-5b11d7d0d8c3"
   },
   "outputs": [],
   "source": [
    "task = Threads.@spawn begin\n",
    "    println(\"Thread starting\")\n",
    "    sleep(1)\n",
    "    println(\"Thread stopping\")\n",
    "    42 # result\n",
    "end\n",
    "\n",
    "println(\"Hello!\")\n",
    "\n",
    "println(\"The result is: \", fetch(task))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbv40Ib7bF7v"
   },
   "source": [
    "The `fetch()` function waits for the thread to finish, and fetches the result. You can also just call `wait()` if you don't need the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsK9bt-Hb2IS"
   },
   "source": [
    "Last but not least, you can use channels to synchronize and communicate across tasks, even if they are running across separate threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "sgdNzgkaceEz",
    "outputId": "370dea30-fb7e-4d53-df11-d2a94658101f"
   },
   "outputs": [],
   "source": [
    "ch = Channel()\n",
    "task1 = Threads.@spawn begin\n",
    "    for i in 1:5\n",
    "        sleep(rand())\n",
    "        put!(ch, i^2)\n",
    "    end\n",
    "    println(\"Finished sending!\")\n",
    "    close(ch)\n",
    "end\n",
    "\n",
    "task2 = Threads.@spawn begin\n",
    "    foreach(v->println(\"Received $v\"), ch)\n",
    "    println(\"Finished receiving!\")\n",
    "end\n",
    "\n",
    "wait(task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLOdUrTcV1Lh"
   },
   "source": [
    "For more details about multithreading, check out [this page](https://docs.julialang.org/en/v1/manual/parallel-computing/#man-multithreading-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JfyJjTXX1AM"
   },
   "source": [
    "## Multiprocessing & Distributed Programming\n",
    "Julia can spawn multiple Julia processes upon startup if you specify the number of processes via the `-p` argument. You can also spawn extra processes from Julia itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JtqG4qIhX5Sw",
    "outputId": "9c68c284-3dcf-4f85-f7fe-6023015eac56"
   },
   "outputs": [],
   "source": [
    "using Distributed\n",
    "addprocs(4)\n",
    "workers() # array of worker process ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD9hcmhGfraw"
   },
   "source": [
    "The main process has id 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TlsjSMFZe3Ae",
    "outputId": "61f1816e-079c-4113-ff93-d349ed13f792"
   },
   "outputs": [],
   "source": [
    "myid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAS3Q8ohfvwg"
   },
   "source": [
    "The `@everywhere` macro lets you run any code on all workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "lmhHLhtbenY5",
    "outputId": "90f1d535-9a9e-4856-98a6-d2fa9245809a"
   },
   "outputs": [],
   "source": [
    "@everywhere println(\"Hi! I'm worker $(myid())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyQQ0Td2hAuQ"
   },
   "source": [
    "You can also execute code on a particular worker by using `@spawnat <worker id> <statement>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mmc1-zfBgsur",
    "outputId": "4b2a4b2b-f060-40ea-b86e-ce54835dc80a"
   },
   "outputs": [],
   "source": [
    "@spawnat 3 println(\"Hi! I'm worker $(myid())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZaV4ptbk4sB"
   },
   "source": [
    "If you specify `:any` instead of a worker id, Julia chooses the worker for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "i6C7ydoBkyln",
    "outputId": "bdce4dc3-fbec-42f8-a270-6676e69ed3c0"
   },
   "outputs": [],
   "source": [
    "@spawnat :any println(\"Hi! I'm worker $(myid())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZMDIATZg9Ug"
   },
   "source": [
    "Both `@everywhere` and `@spawnat` return immediately. The output of `@spawnat` is a `Future` object. You can call `fetch()` on this object to wait for the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ml5TBZLQf2oY",
    "outputId": "91af772e-3491-44d4-9146-9b81a13ebac0"
   },
   "outputs": [],
   "source": [
    "result = @spawnat 3 1+2+3+4\n",
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8rR6jBdhuvT"
   },
   "source": [
    "If you import some package in the main process, it is <u>not</u> automatically imported in the workers. For example, the following code fails because the worker does not know what `pyimport` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "s89GQtv5iNfP",
    "outputId": "361aa179-938b-4c80-bce3-f9ddd01f35dd"
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "\n",
    "result = @spawnat 4 (np = pyimport(\"numpy\"); np.log(10))\n",
    "\n",
    "try\n",
    "    fetch(result)\n",
    "catch ex\n",
    "    ex\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-wFnpu7inDg"
   },
   "source": [
    "You must use `@everywhere` or `@spawnat` to import the packages you need in each worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eseDsHvzna1R",
    "outputId": "3c9d9bad-d2d5-465e-f2b5-bd68e35f7b3e"
   },
   "outputs": [],
   "source": [
    "@everywhere using PyCall\n",
    "\n",
    "result = @spawnat 4 (np = pyimport(\"numpy\"); np.log(10))\n",
    "\n",
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nzk3gbLOnqTx"
   },
   "source": [
    "Similarly, if you define a function in the main process, it is <u>not</u> automatically available in the workers. You must define the function in every worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vrvbWhDMnzdX",
    "outputId": "8f7103d8-4095-4f66-88d7-06854b21cc3e"
   },
   "outputs": [],
   "source": [
    "@everywhere addtwo(n) = n + 2\n",
    "result = @spawnat 4 addtwo(40)\n",
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9skIo6pnoikr"
   },
   "source": [
    "You can pass a `Future` to `@everywhere` or `@spawnat`, as long as you wrap it in a `fetch()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "IjovCqk7n_cu",
    "outputId": "8c28e447-69cf-4b5b-aa73-ea57e8ec57cd"
   },
   "outputs": [],
   "source": [
    "M = @spawnat 2 rand(5)\n",
    "result = @spawnat 3 fetch(M) .* 10.0\n",
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4YeovYto60s"
   },
   "source": [
    "In this example, worker 2 creates a random array, then worker 3 fetches this array and multiplies each element by 10, then the main process fetches the result and displays it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUl0Nj9dV-IW"
   },
   "source": [
    "## GPU\n",
    "Julia has excellent GPU support. As you may know, GPUs are devices which can run thousands of threads in parallel. Each thread is slower and more limited than on a CPU, but there are so many of them that plenty of tasks can be executed much faster on a GPU than on a CPU, provided these tasks can be parallelized.\n",
    "\n",
    "Let's check which GPU device is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "DTKc9IFB-eum",
    "outputId": "f6c373d7-9597-4c6f-dca5-d869af5a1f31"
   },
   "outputs": [],
   "source": [
    ";nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULS7Jn6vws2-"
   },
   "source": [
    "If you're running on Colab, your runtime will generally have an Nvidia Tesla K80 GPU with 12GB of RAM installed, but sometimes other GPUs like Nvidia Tesla T4 16GB, or Nvidia Tesla P100).\n",
    "\n",
    "If no GPU is detected, go to _Runtime_ > _Change runtime type_, set _Hardware accelerator_ to _GPU_, then go to _Runtime_ > _Factory reset runtime_, then reinstall Julia by running the first cell again, then reload the page and come back here). If you're running on your own machine, make sure you have a compatible GPU card installed, with the appropriate drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzVnsDN--gRr"
   },
   "source": [
    "Now let's create a large matrix and time how long it takes to square it on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-rbfON6gWYwe",
    "outputId": "8fd49f1d-187d-48f8-b642-dbb9fbc69371"
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "M = rand(2^11, 2^11)\n",
    "\n",
    "function benchmark_matmul_cpu(M)\n",
    "    M * M\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_matmul_cpu(M) # warm up\n",
    "@btime benchmark_matmul_cpu($M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRO3dOh1lnVg"
   },
   "source": [
    "Notes:\n",
    "* For benchmarking, we wrapped the operation in a function which returns `nothing`.\n",
    "* Why do we have a \"warm up\" line? Well, since Julia compiles code on the fly the first time it is executed, it's good practice to execute the operation we want to benchmark at least once before starting the benchmark, or else the benchmark will include the compilation time.\n",
    "* We used `$M` instead of `M` on the last line. This is a feature of the `@btime` macro: it evaluates `M` before benchmarking takes place, to avoid the extra delay that is incurred when [benchmarking with global variables](https://docs.julialang.org/en/latest/manual/performance-tips/#Avoid-global-variables-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-nbiuYDtGlb"
   },
   "source": [
    "Now let's benchmark this same operation on the GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3hIWY1O_WE6a",
    "outputId": "0f953737-6706-4338-b508-38bff61587c0"
   },
   "outputs": [],
   "source": [
    "using CUDA\n",
    "\n",
    "# Copy the data to the GPU. Creates a CuArray:\n",
    "M_on_gpu = cu(M)\n",
    "\n",
    "# Alternatively, create a new random matrix directly on the GPU:\n",
    "#M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
    "\n",
    "function benchmark_matmul_gpu(M)\n",
    "    CUDA.@sync M * M\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_matmul_gpu(M_on_gpu) # warm up\n",
    "@btime benchmark_matmul_gpu($M_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFEBz1hkZ6Ox"
   },
   "source": [
    "That's _much_ faster (185x faster in my test on Colab with an NVidia Tesla P100 GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbjxRKWc1-nR"
   },
   "source": [
    "Importantly:\n",
    "* Before the GPU can work on some data, it needs to be copied to the GPU (or generated there directly).\n",
    "* the `CUDA.@sync` macro waits for the GPU operation to complete. Without it, the operation would happen in parallel on the GPU, while execution would continue on the CPU. So we would just be timing how long it takes to _start_ the operation, not how long it takes to complete.\n",
    "* In general, you don't need `CUDA.@sync`, since many operations (including `cu()`) call it implicitly, and it's usually a good idea to let the CPU and GPU work in parallel. Typically, the GPU will be working on the current batch of data while the CPU works on preparing the next batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lja576nUWXLU"
   },
   "source": [
    "Of course, the speed up will vary depending on the matrix size and the GPU type. Moreover, copying the data from the CPU to the GPU is often the slowest part of the operation, but we only benchmarked the matrix multiplication itself. Let's see what we get if we include the data transfer in the benchmark:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMegVhMzBtPz"
   },
   "source": [
    "That's still much faster than on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdvtwJAu3aOU"
   },
   "source": [
    "Let's check how much RAM we have left on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "599aiP0s3c4y",
    "outputId": "e3297190-a7c6-49d4-d460-8f14a5133185"
   },
   "outputs": [],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86XHVDDrDJjp"
   },
   "source": [
    "Julia's Garbage Collector will free CUDA arrays like any other object, when there's no more reference to it. However, `CUDA.jl` uses a memory pool to make allocations faster on the GPU, so don't be surprised if the allocated memory on the GPU does not go down immediately. Moreover, IJulia keeps a reference to the output of each cell, so if you let any cell output a `CuArray`, it will only be released when you execute `Out[<cell number>]=0`. If you want to force the Garbage Collector to run, you an run `GC.gc()`. To reclaim memory from the memory pool, use `CUDA.reclaim()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VPoO6-h_tVBE",
    "outputId": "ca8e192e-2d45-4dbd-c60f-cdfbdc31018a"
   },
   "outputs": [],
   "source": [
    "GC.gc()\n",
    "CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ndcNywPSE0D9"
   },
   "source": [
    "Many other operations are implemented for `CuArray` (`+`,  `-`, etc.) and dotted operations (`.+`, `exp.()`, etc). Importantly, loop fusion also works on the GPU. For example, if we want to compute `M .* M .+ M`, without loop fusion the GPU would first compute `M .* M` and create a temporary array, then it would add `M` to that array, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "psC2K-M_F0w9",
    "outputId": "2831edea-a646-43d8-d272-35fa13b92093"
   },
   "outputs": [],
   "source": [
    "function benchmark_without_fusion(M)\n",
    "    P = M .* M\n",
    "    CUDA.@sync P .+ M\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_without_fusion(M_on_gpu) # warm up\n",
    "@btime benchmark_without_fusion($M_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTbDFRdJIO9M"
   },
   "source": [
    "Instead, loop fusion ensures that the array is only traversed once, without the need for a temporary array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zHQI4nkHGkLx",
    "outputId": "1ea3c80d-f87b-44f7-b19a-b00b32c8c201"
   },
   "outputs": [],
   "source": [
    "function benchmark_with_fusion(M)\n",
    "    CUDA.@sync M .* M .+ M\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_with_fusion(M_on_gpu) # warm up\n",
    "@btime benchmark_with_fusion($M_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ln5b2NykQCsD"
   },
   "source": [
    "That's _much_ faster (75% faster in my test on Colab). 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9HAHfceIa3U5"
   },
   "source": [
    "Lastly, you can actually **write your own GPU kernels in Julia**! In other words, rather than using GPU operations implemented in the `CUDA.jl` package (or others), you can write Julia code that will be compiled for the GPU, and executed there. This can occasionally be useful to speed up some algorithms where the standard kernels don't suffice. For example, here's a GPU kernel which implements `u .+= v`, where `u` and `v` are two (large) vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lnbRTzgWX0gx",
    "outputId": "40701458-9b62-4947-8f59-f7a86e1270c1"
   },
   "outputs": [],
   "source": [
    "function worker_gpu_add!(u, v)\n",
    "    index = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    index ≤ length(u) && (@inbounds u[index] += v[index])\n",
    "    return\n",
    "end\n",
    "\n",
    "function gpu_add!(u, v)\n",
    "    numblocks = ceil(Int, length(u) / 256)\n",
    "    @cuda threads=256 blocks=numblocks worker_gpu_add!(u, v)\n",
    "    return u\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEnX1i4ooQiN"
   },
   "source": [
    "This code example is adapted from the [`CUDA.jl` package's documentation](https://juliagpu.gitlab.io/CUDA.jl/tutorials/introduction/), which I highly encourage you to check out if you're interested in writing your own kernels. Here are the key parts to understand this example, starting from the end:\n",
    "* The `gpu_add!()` function first calculates `numblocks`, the number of blocks of threads to start, then it uses the `@cuda` macro to spawn `numblocks` blocks of GPU threads, each with 256 threads, and each thread runs `worker_gpu_add!(u, v)`.\n",
    "* The `worker_gpu_add!()` function computes `u[index] += v[index]` for a single value of `index`: in other words, each thread will just update a single value in the vector! Let's see how the index is computed:\n",
    "  * The `@cuda` macro spawned many blocks of 256 threads each. These blocks are organized in a grid, which is one-dimensional by default, but it can be up to three-dimensional. Therefore each thread and each block have an `(x, y, z)` coordinate in this grid. See this diagram from the [Nvidia blog post](https://developer.nvidia.com/blog/even-easier-introduction-cuda/):<br />\n",
    "<img src=\"https://juliagpu.gitlab.io/CUDA.jl/tutorials/intro1.png\" width=\"600\"/>.\n",
    "  * `threadIdx().x` returns the current GPU thread's `x` coordinate within its block (one difference with the diagram is that Julia is 1-indexed).\n",
    "  * `blockIdx().x` returns the current block's `x` coordinate in the grid.\n",
    "  * `blockDim().x` returns the block size along the `x` axis (in this example, it's 256).\n",
    "  * `gridDim().x` returns the number of blocks in the grid, along the `x` axis (in this example it's `numblocks`).\n",
    "  * So the `index` that each thread must update in the array is `(blockIdx().x - 1) * blockDim().x + threadIdx().x`.\n",
    "* As explained earlier, the `@inbounds` macro is an optimization that tells Julia that the index is guaranteed to be inbounds, so there's no need for it to check.\n",
    "\n",
    "Now writing your own GPU kernel won't seem like something only top experts with advanced C++ skills can do: you can do it too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gf6-5tJXRCm0"
   },
   "source": [
    "Let's check that the kernel works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7mGsSWYL2iW"
   },
   "outputs": [],
   "source": [
    "u = rand(2^20)\n",
    "v = rand(2^20)\n",
    "\n",
    "u_on_gpu = cu(u)\n",
    "v_on_gpu = cu(v)\n",
    "\n",
    "u .+= v\n",
    "gpu_add!(u_on_gpu, v_on_gpu)\n",
    "\n",
    "@assert Array(u_on_gpu) ≈ u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCZyhpbwNeLQ"
   },
   "source": [
    "Yes, it works well!\n",
    "\n",
    "Note: the `≈` operator checks whether the operands are approximately equal within the float precision limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Koqs9GrqRHeW"
   },
   "source": [
    "Let's benchmark our custom kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g2_7SawNR4Jb",
    "outputId": "c33eb08e-4eb3-493a-f0bb-e2b4bf4e8717"
   },
   "outputs": [],
   "source": [
    "function benchmark_custom_assign_add!(u, v)\n",
    "    CUDA.@sync gpu_add!(u, v)\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_custom_assign_add!(u_on_gpu, v_on_gpu)\n",
    "@btime benchmark_custom_assign_add!($u_on_gpu, $v_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hl0_1Km9SyD7"
   },
   "source": [
    "Let's see how this compares to `CUDA.jl`'s implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vogLKdtEO9l6",
    "outputId": "fc8d07e3-1499-4a11-c2a6-b65cf08f22b9"
   },
   "outputs": [],
   "source": [
    "function benchmark_assign_add!(u, v)\n",
    "    CUDA.@sync u .+= v\n",
    "    return\n",
    "end\n",
    "\n",
    "benchmark_assign_add!(u_on_gpu, v_on_gpu)\n",
    "@btime benchmark_assign_add!($u_on_gpu, $v_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKRNLPIRcbCd"
   },
   "source": [
    "How about that? Our custom kernel is faster than `CUDA.jl`'s kernel! But to be fair, our kernel would not work with huge vectors, since there's a limit to the number of blocks & threads you can spawn (see [Table 15](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications) in CUDA's documentation). To support such huge vectors, we need each worker to run a loop like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zi8-UvGocWOK",
    "outputId": "367b633c-7a83-4f4a-b379-c35c095ca698"
   },
   "outputs": [],
   "source": [
    "function worker_gpu_add!(u, v)\n",
    "    index = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    stride = blockDim().x * gridDim().x\n",
    "    for i = index:stride:length(u)\n",
    "        @inbounds u[i] += v[i]\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtQNhlw1c3zo"
   },
   "source": [
    "This way, if `@cuda` is executed with a smaller number of blocks than needed to have one thread per array item, the workers will loop appropriately.\n",
    "\n",
    "This should get you started! For more info, check out [`CUDA.jl`'s documentation](https://juliagpu.gitlab.io/CUDA.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FA9DFoEuiGib"
   },
   "source": [
    "# Command Line Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1nlKvCZhVo7"
   },
   "source": [
    "Command line arguments are available via `ARGS`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ysg_6WElhY7-",
    "outputId": "3a6206a7-c577-4a59-e118-650ea75bcdcd"
   },
   "outputs": [],
   "source": [
    "ARGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRe_1ovZhdqh"
   },
   "source": [
    "Unlike Python's `sys.argv`, the first element of this array is <u>not</u> the program name. If you need the program name, use `PROGRAM_FILE` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2z3obYZghrHL",
    "outputId": "5bf9f50f-f126-4f72-b9e9-8dfbbdb258d5"
   },
   "outputs": [],
   "source": [
    "PROGRAM_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnKMaPm8r1XC"
   },
   "source": [
    "You can get the current module, directory, file or line number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZIou0Kgbr5mu",
    "outputId": "2367725b-00d2-4f7e-dbd4-ed6657474b0e"
   },
   "outputs": [],
   "source": [
    "@__MODULE__, @__DIR__, @__FILE__, @__LINE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahpsLiV_hBLi"
   },
   "source": [
    "The equivalent of Python's `if __name__ == \"__main__\"` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPUUlZG6g_A5"
   },
   "outputs": [],
   "source": [
    "if abspath(PROGRAM_FILE) == @__FILE__\n",
    "    println(\"Starting of the program\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8g43x6YYiKLf"
   },
   "source": [
    "# Memory Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-YehjM8iMmn"
   },
   "source": [
    "Let's check how many megabytes of RAM are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O80YQtSciPvV",
    "outputId": "d8466741-c6b3-4cb6-ba7f-381e9bae51be"
   },
   "outputs": [],
   "source": [
    "free() = println(\"Available RAM: \", Sys.free_memory() ÷ 10^6, \" MB\")\n",
    "\n",
    "free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bxKvaTpfdO5j"
   },
   "source": [
    "If a variable holds a large object that you don't need anymore, you can either wait until the variable falls out of scope, or set it to `nothing`. Either way, the memory will only be freed when the Garbage Collector does its magic, which may not be immediate. In general, you don't have to worry about that, but if you want, you can always call the GC directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "j0M8Oka3fod6",
    "outputId": "83f7da65-406c-4a0e-fb79-5627e81f2b44"
   },
   "outputs": [],
   "source": [
    "function use_ram()\n",
    "    M = rand(10000, 10000) # use 400+MB of RAM\n",
    "    println(\"sum(M)=$(sum(M))\")\n",
    "end # M will be freed by the GC eventually after this\n",
    "\n",
    "use_ram()\n",
    "\n",
    "M = rand(10000, 10000) # use 400+MB of RAM\n",
    "println(\"sum(M)=$(sum(M))\")\n",
    "M = nothing\n",
    "\n",
    "GC.gc() # rarely needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8Fbip9OpRyD",
    "outputId": "1879a5e1-1209-4752-b86f-66a085ec64b8"
   },
   "outputs": [],
   "source": [
    "free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsYZBLwwpqEG"
   },
   "source": [
    "# Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QOVcDKLptgh"
   },
   "source": [
    "I hope you enjoyed this introduction to Julia! I recommend you join the friendly and helpful Julia community on Slack or Discourse.\n",
    "\n",
    "Cheers!\n",
    "\n",
    "Aurélien Geron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3IpBJjap9Sm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Julia_for_Pythonistas.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
